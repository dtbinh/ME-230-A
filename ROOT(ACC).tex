%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\usepackage{graphicx}      % include this line if your document contains figures
\usepackage{siunitx}
\sisetup{per=slash, load=abbr}

    % GRAPHICS
\usepackage{tikz}


\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\usepackage{comment}

\usepackage{epstopdf}
\usepackage{comment}
\usepackage{subfig}
\usepackage{pgfplots}
%\pgfplotsset{width=7cm,compat=1.3}
%\usepackage{subcaption}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{amsmath}               
  {
    \newtheorem{assumption}{\textbf{Assumption}}
    
  }

\newcommand\norm[1]{\left\lVert#1\right\rVert}
\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.

%In case you encounter the following error:
%Error 1010 The PDF file may be corrupt (unable to open PDF file) OR
%Error 1000 An error occurred while parsing a contents stream. Unable to analyze the PDF file.
%This is a known problem with pdfLaTeX conversion filter. The file cannot be opened with acrobat reader
%Please use one of the alternatives below to circumvent this error by uncommenting one or the other
%\pdfobjcompresslevel=0
%\pdfminorversion=4

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
%\usepackage{amsmath} % assumes amsmath package installed
%\usepackage{amssymb}  % assumes amsmath package installed

\title{\LARGE \bf
EUA-MPC: Mothin planning for robots in industrial HRI system  
}


\author{ Jessica Leu$^{1}$% <-this % stops a space
\thanks{$^{1}$Jessica Leu is with the Department of Electrical Engineering, University of California,
Berkeley, CA 94720 USA{\tt\small jess.leu24@berkeley.edu}}%
}


\begin{document}



\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

Real-time, safe, and stable motion planning in dynamic HRI system remains challenging due to the non-convexity and time variance of the problem. This paper presents an approach to formulate a set of dynamic environments in a environment uncertainty adaptive model predictive control (EUA-MPC) problem. To achieve this, a filtering-based method, which guarantees closed-loop stability of MPC, is used to predict the motion of the human. Also, the closed-loop performance is investigated using a notion of $M$-analysis, which guarantees finite convergence (at least $M$ steps ahead) of the open-loop trajectories to the closed-loop trajectory. With such notion, we verify the performance of the EUA-MPC at every executing time step through extensive simulations and experiments. With the proposed EUA-MPC, it is shown that closed-loop cost is reduced and open-loop trajectories converge faster to the closed-loop trajectory.
\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{INTRODUCTION}

The development of intelligent robots and autonomous vehicles is craving for real-time, safe, and stable motion planning in cluttered dynamic environments. For example, an automated guided vehicle (AGV) in industrial human-robot interaction (HRI) system \cite{wu2004modeling}, needs to decide in real time how to bypass multiple human workers and a set of obstacles in the environment in order to approach its target efficiently \cite{wang2009autonomous,oleari2014industrial}. 

In literature, motion planning algorithms usually fall into three categories: graph-search based algorithm, sampling-based algorithm, and optimization-based algorithm. Among these algorithms, this paper focus on model predictive control (MPC) \cite{rawlings1999tutorial}, an optimization-based algorithm. MPC has been widely adopted both in academia research and in industrial applications. The fact that MPC controller observes the environment every time before solving the optimization problem allows the system to adjust and re-plan according to the changes of the environment. Its ability to handle input and state constraints also makes it popular in addressing motion planning problems. If the problem is a convex MPC problem, the stability of the closed loop system can be guaranteed by modifying prediction horizon, adding terminal cost, adding terminal equality constraint, or using terminal set constraint instead \cite{mayne2000constrained}, \cite{limon2006stability}. These methods can guarantee that the calculated commands and the resulting states are bounded in the presence of bounded disturbance. One common application of motion planning MPC problem is autonomous vehicles \cite{borrelli2005mpc}. In literatures, stability is guaranteed by setting stability boundary for the control system, i.e., stability is quantified at several vehicle speeds.

However, two nature of motion planning in dynamic environments contaminated the stability properties of MPC. First, the existence of obstacles in the environment introduces non-convex state constraints, which results in non-convex MPC problems. It is still challenging to obtain real-time, safe and stable solutions for non-convex MPCs. An efficient optimization algorithm, i.e., the convex feasible set (CFS) algorithm \cite{liu2018convex}, has been proposed to obtain a safe open-loop trajectory in real time. However, there are many local optima due to non-convexity. Therefore, even the trajectory calculated by CFS at each MPC time step is feasible and smooth, it is possible that the trajectories planned at different time steps will jump around multiple local optima causing the implemented trajectory to be dynamically unreasonable for the robot. Dynamically unreasonable closed-loop trajectory will cause the robot to execute violent or zigzagging movement that is harmful to the robot's motors and also scares human in the environment. A standard analytical approach to verify properties of non-convex MPC is needed so that we can estimate the MPC closed-loop performance and stability. 

\begin{comment}
Some work focused on MPC problems with non-convex cost function using the sequential convex optimization method \cite{hovgaard2013nonconvex}. Although the result is promising, the difficulty of ensuring closed-loop stability and analyzing controller performance for non-convex MPC is also mentioned in the literature. 

A standard analytical approach to verify properties of non-convex MPC is needed so that we can estimate whether the trajectory implemented by the MPC controller is smooth and desirable, i.e., the trajectories planned at different time steps do not jump around multiple local optima, and the result of this analysis can serve as an indication of the MPC controllerâ€™s stability properties.
\end{comment}

The second problem is that the constraints in the optimization change continuously through out time due to the change in the environment. The fact that optimization problems are sensitive to the constraints make the open-loop trajectory at each time step varies largely. This again will result in dynamically unreasonable closed-loop trajectory. Fortunately, with some assumptions, it is possible to formulate the uncertainties in the MPC problem in a proper way. Some works have been focusing on dealing with uncertainties in MPC problems  \cite{ chisci2001systems, kuwata2007distributed}. In these papers, systems under persistent disturbance can be controlled by robust MPC. However, a more common scenario in motion planning problems is to have uncertainties in the environment, e.g., environment that has speed-variant objects. Therefore, a probabilistic model of objects' future movement is needed. In \cite{luders2010chance}, Stochastic MPC deals with probability constraints to handle uncertainties in the environment. Another approach is to directly predict the object's future motion. This paper focuses on industrial HRI environment \cite{goodrich2008human, kruse2013human}, where the uncertainties in the environment are usually caused by human workers. It is clear that although the workers do not explicitly reveal their intention, it is still possible to predict their future motion based on past observations \cite{butepage2017anticipating}. In \cite{kumar2013learning}, Bayesian filter is used for motion prediction given observation in the past and the state transition model. 




The contribution of this paper is to provide a new MPC, environment uncertainty adaptive MPC (EUA-MPC), which observes the environment and predicts human intention to construct the state space for the optimization problem at each executing time step. The proposed EUA-MPC can better deal with environment uncertainties which addresses the limitation of traditional MPC. To show that EUA-MPC performs better than traditional MPS owing to a better knowledge of the dynamic environment, the closed-loop cost of the EUA-MPC is compared with the traditional MPC. It is also assured that EUA-MPC is stable theoretically in the seance of Lyapunov in a set of common factory scenarios. A new notion of closed-loop stability property called $M$-analysis  \cite{jess2018mstable} is used to examine the open-loop trajectory convergence, which serve as another indicator of the closed-loop performance of the EUA-MPC. Simulation studies are performed to test the performance of the implemented EUA-MPC. Finally, experiment is carried to verify the algorithm.

The remainder of the paper is organized as follows. Section II provides the problem formulation. Section III shows simulation results. Section IV shows the experiment result (code is publicly available at {\tt\small github.com/msc-berkeley/MPC-CFS-Matlab}). Section V concludes the paper.

\section{PROBLEM FORMULATION}

\begin{figure}[t]
\begin{center}
\includegraphics[width=8cm]{src/MPCstruc.png}
\caption{The execution structure of MPC}
\label{fig: mpc}
\end{center}
\end{figure}

\begin{figure}[t]
      \centering
      \includegraphics[width=6cm]{plot/system.pdf}
      \caption{The overall system control design. }
      \label{fig:MPCsystem}
\end{figure}

\begin{figure}[t]
      \centering
      \includegraphics[width=5cm]{plot/slack.pdf}
      \caption{Illustration of the slack variable. }
      \label{fig:slack}
\end{figure}

\subsection{Traditional Non-convex MPC and Notations}
In MPC (Fig.~\ref{fig:MPCsystem}), at each time step $t$, a future trajectory will be planned by solving an optimization problem. This trajectory is denoted as $\mathbf{x}_{k} := [x_k, x_{k+1},x_{k+2},\cdots,x_{k+H}]$ where the state, $x_k$, is called the $k^{th}$ action location. $H$ is the prediction horizon. In this paper, $x_k= [x(k)\quad y(k)]^{\intercal}$ that contains the $x$ and $y$ coordinate of the robot's location in 2-dimensional Cartesian space at time step $t=k$. Note that $x_k$ corresponds to the current position at time step $t=k$. The trajectory will then be executed and the robot will go to $x_{k+1}$, the $k+1^{th}$ action location, which is the planned action location for the robot at time step $t=k+1$. The sampling time between two time steps is a constant, denoted as $\Delta t$. After reaching the next action location, the robot will again solve the optimization problem and plan a new trajectory and repeat the process. To avoid confusion, the current time step can also be marked as superscript in some cases , e.g., $x_{k+1}^k$ means the planned action location $x_{k+1}$ at time step $t=k$.

At time step $t=k$, given the current state, denoted as $x_0(t=k) = (x,y)|_{t=k}$, the following optimization needs to be solved to obtain $\mathbf{x}_k$,


\begin{eqnarray}
&\min_{\mathbf{x}_{k}} & J(\mathbf{x}_k),\\
&s.t.& x_{k+i}\in\Gamma,\forall i=1,\ldots,H,\\
&&         x_{k}=x_0(k).
\end{eqnarray}

The current state is measured and assigned to the first entry of $\mathbf{x}_{k}$. Note that the optimization problem for each time step is time-invariant. There are two assumptions in this formulation: 

\begin{assumption}[Cost]
\textit{The cost function is convex and regular, and has the following form}
\begin{equation}
J(\mathbf{x}_k) = C_1\|\mathbf{D}\mathbf{x}_k-\mathbf{d}\|_{2}^2 + C_2 \|\mathbf{V}\mathbf{x}_k-\mathbf{v}_{ref}\|_2^2 +C_3\|\mathbf{A}\mathbf{x}_{k}\|_2^2.  
\end{equation}
\end{assumption}
Here $C_1$ is the coefficient of the first term, which penalizes the robot's deviation from a reference line so that the robot output trajectory is not too irregular. Matrix $\mathbf{D}$ is a projection matrix that extract all $y$'s from $\mathbf{x}_k$. $C_2$ is the coefficient of the second term, which penalizes the speed profile of the planned trajectory with regard to a constant speed so that the robot will be time efficient. $\mathbf{V}\mathbf{x}_k$ is the velocity vector. Here, the speed reference is set to be a constant speed going along the positive $x$-axis. $C_3$ is the coefficient of the third term, which penalizes the acceleration of the output trajectory so that the motion will be smooth. $\mathbf{A}\mathbf{x}_{k}$ is the acceleration vector.

\begin{assumption}[Constraint]
\textit{The state constraint $\Gamma$ is non-convex and its complement is a collection of disjoint convex sets, i.e., each of the obstacle-region is itself convex.}
\end{assumption}

Since the robot dynamics is not included in the MPC problem, a tracking controller is needed. The overall system is shown in Fig.~\ref{fig:MPCsystem}. Although the planned trajectory  is feasible, tracking error will occur in real world experiment, causing the state ends up to be infeasible. This results in a violent motion because the control command according to the new planning result will immediately pull the robot out of the infeasible area. In order to avoid such problem, we introduce  $\mathbf{S}^k = [s^k_{k+1},s^k_{k+2},\ldots,s^k_{k+H}]$, the slack variable vector. Introducing slack variables allows the states to violate the original constraint, which is the margin boundary of the obstacles (Fig.~\ref{fig:slack}). However these slack variables are also added to the cost function so that the violation is penalized \cite{chen2018foad}. The new problem is shown in the following:

\begin{eqnarray}
&\min_{\mathbf{x}_{k}} & J(\mathbf{x}_k) + \|\mathbf{S^k}\|_{2}^2 ,\\
&s.t.& x_{k+i} \in\Gamma(s^k_{k+i}),\forall i=1,\ldots,H,\\
&&         x_{k}=x_0(k).
\end{eqnarray} 

The final trajectory is $[x_k^k,x_{k+1}^{k+1},\ldots]$, which is equivalent to $[x_{k}^{k-1},x_{k+1}^{k},\ldots]$ (Fig.~\ref{fig: mpc}). As the problem is non-convex, it is possible that the planned trajectories calculated at different time steps enter into different local optima, hence the stability is hard to characterize. 




\subsection{The Convex Feasible Set Algorithm}
Because the problem we are solving has non-convex state constraints, the problem is a non-convex MPC problem. Here we solve the optimization problem at each MPC time step using the convex feasible set algorithm (CFS), which iteratively solve a sequence of sub-problems of the original non-convex problem using convex constraints, e.g., convex feasible set. The CFS algorithm in the MPC structure uses the previous solution, the planned action locations, as a reference. The convex feasible set for a reference point $x_r$ is computed as $\mathcal{F}(x_r) = \{x:A(x_r)x\leq b(x_r)\}$ where $A(x_r)$ is a matrix and $b(x_r)$ is a column vector. 
At time step $k+1$, the reference is set as $\mathbf{x}_{k+1}^{r}=[x_{k+1}^{k},x_{k+2}^{k},\ldots,x_{k+H}^k, x_{k+H+1}^*]$ where
\begin{equation}
\begin{split}
x_{k+H+1}^* & = \arg\min_{x_{k+H+1}} \|x_{k+H+1}\|_Q^2+\|x_{k+H}^k-x_{k+H+1}\|_R^2 \\
 & +\|x_{k+H-1}^k -2x_{k+H}^k+x_{k+H+1}\|_P^2\text{.}
\end{split}
\end{equation}
If $x_{k+H+1}^*\in\Gamma$, then the optimal solution is $\mathbf{x}_{k+1}^o = \mathbf{x}_{k+1}^r$.  If $x_{k+H+1}^*\notin\Gamma$, denote the feasible solution as 
\begin{equation}
\begin{split}
\bar{x}_{k+H+1} & = \arg\min_{x_{k+H+1}\in\Gamma} \|x_{k+H+1}\|_Q^2+\|x_{k+H}^k-x_{k+H+1}\|_R^2 \\
 & +\|x_{k+H-1}^k -2x_{k+H}^k+x_{k+H+1}\|_P^2 \text{.}
\end{split}
\end{equation}

Moreover, denote \\$\mathbf{x}_{k+1}^{u}:=[x_{k+1}^{k},x_{k+2}^{k},\ldots,x_{k+H}^k, \bar x_{k+H+1}]$. 

Because of the construction above, the optimal solution is $\mathbf{x}_{k+1}^{o}$ at step $k+1$ satisfies that
\begin{eqnarray}
\mathbf{x}_{k+1}^{o} = \arg\min_{x_{k+i}\in \mathcal{F}(x_{k+i}^o)}J(\mathbf{x}_{k+1}).
\end{eqnarray}
Note that $J(\mathbf{x}_{k+1}^{r})\leq J(\mathbf{x}_{k+1}^{o})\leq J(\mathbf{x}_{k+1}^{u})$, therefore, the cost of the trajectory is always bounded. 
The executed trajectory is from those $\mathbf{x}_{k+1}^{o}$ for different $k$.

\begin{comment}
\subsection{Converging property with CFS}
In this paper, we will show that the system is stable through simulation. Theoretical proof is left as future work. But here we sketch the procedures. First, we can show that at two consecutive time steps, the difference between the early state should be strictly smaller than the difference between any future state, i.e., $\|x_{k+i}^{k+1}-x_{k+i}^k\|<\lambda\|x_{k+i+1}^{k+1}-x_{k+i+1}^k\|$ for some $\lambda<1$ and for $i$ sufficiently small. Then we can show that the state is bounded and the difference between the same state at different time steps keeps decreasing.
%the KKT condition is satisfied, i.e.,
%\begin{eqnarray}
%2Qx_{k+i}^k +2R(2x_{k+i}^k-x_{k+i-1}^k-x_{k+i+1}^k) + \eta_{k+i}^k A(x_{k+i}^k) \nonumber\\
%= 0,\forall i=1,\ldots,H
%\end{eqnarray}
%where $\eta_{k+i}^k$ is the Lagrangian multiplier such that $\eta_{k+i}^k\geq 0$ and $\eta_{k+i}^k= 0$ if and only if $A(x_{k+i}^k)x_{k+i}^k= b(x_{k+i}^k)$.
%
%Hence
%\begin{eqnarray}
%(Q+2R)(x_{k+i}^{k+1}-x_{k+i}^k)=R(x_{k+i-1}^{k+1}-x_{k+i-1}^k)\\+R(x_{k+i+1}^{k+1}-x_{k+i+1}^k)-(\eta_{k+i}^{k+1} A(x_{k+i}^{k+1})-\eta_{k+i}^k A(x_{k+i}^k))
%\end{eqnarray}
%
%Claim that $\|x_{k+i}^{k+1}-x_{k+i}^k\|<\lambda\|x_{k+i+1}^{k+1}-x_{k+i+1}^k\|$ for some $\lambda<1$.
\end{comment}
\subsection{Human Movement Prediction and Tracking}
In a factory setting, human workers and mobile robots usually have other tasks to complete after stopping from moving. This means they are going to stay in an area for an amount of time which is likely long enough for the ego robot to consider them as static objects with margin, and plan a path to go around them. Therefore, it is important to know whether the obstacle is going to stop. Denote the past position of the obstacle at time $t$ to be $x_{obs}(t)$, the past path of the obstacle is $\mathbf{h}_{obs}^k = [x_{obs}(1), x_{obs}(2),\ldots, x_{obs}(k)]^\top$. With $\mathbf{h}_{obs}^k$, denote the probability for the obstacle to continue moving and to stop to be $p_{go}(k)$ and $p_{stop}(k)$ respectively ($p_{go}(k)+p_{stop}(k)=1$). $r_1$ and $r_2$ are the learning rates ($r_1 >1 $ and $0<r_2<1$) and $b$ is the bias term. We have a the prediction algorithm: 

\begin{algorithm}
\caption{The prediction algorithm}\label{alg:euclid}
\begin{algorithmic}[1]
\Procedure{MovementPred}{$\mathbf{h}_{obs}^k,p_{go}(k-1), p_{stop}(k-1)$}
\State Acc $\gets getAcc(\mathbf{h}_{obs}^k)$
\State endVel $\gets PredictEndVel(Acc,x_{obs}(k))$
\If {endVel $ \leq $ threshold}
    \State $w_{go} \gets r_1p_{go}(k-1)$
    \State $w_{stop} \gets r_2p_{stop}(k-1)+b$
\Else
    \State $w_{go} \gets r_2p_{go}(k-1)+b$
    \State $w_{stop} \gets r_1p_{stop}(k-1)$
    
\EndIf
\State $p_{go}(k), p_{stop}(k) \gets normalize(w_{go},w_{stop})$
\State \textbf{return} $p_{go}(k), p_{stop}(k)$
\EndProcedure
\end{algorithmic}
\end{algorithm}

Although the worker/robot has stopped, it is still possible that the he/she will have movement within the working area. Therefore, the ego robot needs to know potentially how big the area is by observing the movement when the worker/robot is working. A naive Bayesian filter-based method is presented to track the obstacle (e.g., other moving robots or human workers) and give a safety margin according to the past movements that the robot should keep from the obstacle .

Each past position has an associated weight $p(x_{obs}(k))$, and the weight vector for $\mathbf{h}_{obs}^k$ is $\mathbf{p}_{obs}^k = [p(x_{obs}(1)), p(x_{obs}(2)),\ldots, p(x_{obs}(k))]^\top$. In each executing time step, $\mathbf{p}_{obs}^k$ is updated:
\begin{equation}
\begin{split}
\mathbf{p'}_{obs}^k =& \big[\;[\;\gamma\mathbf{p}_{obs}^{k-1}]^\top \;1\; \big]^\top, \\
\mathbf{p}_{obs}^k =& \frac{\mathbf{p'}_{obs}^k}{\norm{ \mathbf{p'}_{obs}^k }_1},
\end{split}
\end{equation}
where $\gamma$ is the discount constant ($\gamma < 0 $). Denote the uncertainty index as $\sigma(k) = std({\mathbf{p}_{obs}^k}^\top \mathbf{h}_{obs}^k)$. Path that has bigger position change for the last several time steps will result in larger $\sigma(k)$. This can serve as an indicator of position uncertainty in the future under the assumption that the current jumpy movement will be passed on at least to the next time step.  




\subsection{State Space Formulation and Stability}
From the previous section, we divided the obstacle movement into two mode, moving mode and working (stop) mode. Since it is unrealistic to conclude anything when the obstacle is still in the moving mode, we focus on the working mode. Denote $k_w$ to be the time when the worker/robot switch to working mode. In the following, we construct the state space during working mode ($k>k_{w}$) with the information presented in the previous section. 
Denote the high-dimensional obstacle region in the open-loop trajectory space at each executing time step as $\mathbf{O}^t(x_0(k),\sigma(k))$. Consider a special case where the obstacle is moving back and forth in the working area, with proper initialization of $\mathbf{O}^0$, $\mathbf{O}^t$ satisfies the relationship $\mathbf{O}^k \subseteq \mathbf{O}^{k-1}$ for all $k>k_{working}$. Denote $\Gamma^k$ as the complement of $\mathbf{O}^k$ such that $\mathbf{x}_k \in \Gamma^k$ and $\Gamma^{k-1} \subseteq \Gamma^k$ for all $k>k_{working}$. The EUA-MPC problem is:

\begin{eqnarray}
J^*(x_0(k))=&\min_{\mathbf{x}_{k}} & J(\mathbf{x}_k) + \|\mathbf{S^k}\|_{2}^2 ,\\
&s.t.& \mathbf{x}_k \in \Gamma^k(x_0(k),\sigma(k),\mathbf{S^k}),\\
&&         x_{k}=x_0(k).
\end{eqnarray} 

Since the cost function is time-invariant and quadratic, $\Gamma^{k-1} \subseteq \Gamma^k$ implies that the cost of the optimal open-loop trajectory $J^*(x_k) \leq J^*(x_{k-1})$ for all $k>k_{w}$, and therefore, EUA-MPC is stable in the seance of Lyapunov for all $k>k_{w}$ before encountering a new obstacle.  

\subsection{Overall System}

The overall system (Fig.~\ref{fig:MPCsystem}) goes through a process as shown below in ever executing time step.

\begin{algorithm}
\caption{The prediction algorithm}\label{alg:euclid}
\begin{algorithmic}[1]
\While{EUA-MPC} 
\State $GetInformation()$
\If {ObstacleMode $== moving$}
    \State traditional state space as in (6)
\Else
    \State EUA-state space as in (13)  
\EndIf
\State $\mathbf{x}_{ref} \gets Initialize(x_0(k))$
\State $\mathbf{x}_k \gets CFS(\mathbf{x}_{ref},x_0(k),\Gamma^k)$
\State $[v ,\:\omega]_k^\top \gets LQR(\mathbf{x}_k)$ 
\State ego robot execute control input
\EndWhile
\end{algorithmic}
\end{algorithm}
 

\subsection{$M$-Analysis for analyzing stability properties}
In this paper, we propose a new way, $M$-analysis, to analyzing transient of the planned open-loop trajectory from one planning instance to the next.

\textbf{\textit{Definition 1}} \textit{($M$-stability):}
\textit{We say that an action location, $x_{k}$, is $M$-stable if for $k-M< t\leq k$, the last $M$ time steps at $x_{k}$ satisfy: $(i) \;\|x_{k}^t-x_k^{t-1}\|\leq \|x_k^{t-1}-x_k^{t-2}\|$ or $(ii) \;\bigl|\|x_{k}^t-x_k^{t-1}\|-\|x_k^{t-1}-x_k^{t-2}\|\bigr|\leq \delta$, when $\bigl|\|x_{k}^t-x_k^{t-1}\|\leq \epsilon$ where $\delta$ and $\epsilon$ are small threshold.}


In Fig.~\ref{fig:m-stable}, the pink-orange-color circles are the action location $x_{k}$ planned at different time steps that are  tested for $M$-stable property of $x_{k}$. The conditions imply that the planned state $x_k$ would have smaller and smaller change ($(i)$) or sufficiently small change ($(ii)$) on each predicted action location between consecutive time steps after time step $k-M$. Under the condition that the environment in the future time step is not going to change much, we say that the MPC is $M$-stable if the above inequalities holds for all $k$. This result can also be expressed as saying the output solutions are all close to one local optimum after time step $k-M$. 

Having such property is good for the robot. $M$-stability guarantees that the action location will not change much, and therefore, guarantees smoothness of the output trajectory. If M is sufficiently large, the robot system will not experience sudden change. Moreover, since the planned trajectory is usually tracked by a low-level tracking controller, the larger the $M$ is, the smoother the control command would be.

\begin{figure}[t]
\begin{center}
\includegraphics[width=9cm]{src/Mstable.png}
\caption{Illustration of $M$-analysis.}
\label{fig:m-stable}
\end{center}
\end{figure}

\section{SIMULATION RESULT AND DISCUSSION}
The simulation scenario in this work is similar to that of mobile robots operating in factories. To test our algorithm and see the improvement of the proposed method, two kinds of scenarios will be considered. The goal for the robot is to move along a line, $y=0$, in the positive $x$-axis direction, while maintaining a constant speed which also points along the positive $x$-axis. The first one is a cluster dynamic scenario where the robot will observe a few changes in the environment. The second one is a scenario where a worker walks to a place on the ego robots path and works in the area. 

\begin{comment}
\subsection{Result of scenario with initially unknown moving obstacle}
In this scenario, there exists a moving obstacle, which is not observed by the robot at the beginning. Once the robot sees this obstacle, it also gets the information of the obstacle's dynamics, and therefore, is able to predict the future position of the obstacle and conduct planning accordingly. 


In Fig.~\ref{fig:3_3}, the existence of the third obstacle on the right is unknown to the robot at the beginning. The obstacle is assumed to be moving in constant speed once detected. However, the obstacle will change its speed at some point after detection. In the simulation, after time step $t=20$, the obstacle changes its speed and from moving along negative $x$-axis to positive $y$-axis. From Fig.~\ref{fig:3_3} (b), we can see that the robot adjusts the planned trajectory to best utilize the space once it detects the speed change and avoids the obstacles successfully. From the $M$-analysis plot of this scenario (Fig.~\ref{fig:3_4}), we can also see that the system maintains $15$-settling even though the environment is changing though out time. The result indicates that as long as there is no sudden change accruing close before an action location is executed, the robot can best utilize the new information and successfully plan a smooth trajectory with both traditional MPC and EUA-MPC.

To show the limitation of traditional MPC, an extreme case is tested. We make the blue obstacle oscillate its moving speed between $-1$ and $1$ on the $y$ direction at every time step. The action locations near the obstacle (around $k=40$) have a zigzagging shape and in Fig.~\ref{fig:badM}, these action locations also show a decrease in $M$. This indicates that the trajectory is jumping among local optima and we can say that the MPC controller performance is not as stable compared with the previous scenarios.

\begin{figure}[t]
      \centering
      \subfloat[Simulation result of scenario that has initially unknown moving obstacles (with speed change).\label{fig:3_3}]{\input{plot/move.tex}}\\
      \subfloat[$M$-analysis for scenario that has initially unknown moving obstacles (with speed change).\label{fig:3_4}]{\input{plot/moveM.tex}}\\
      \subfloat[$M$-analysis for scenario that has oscillating moving obstacles.\label{fig:badM}]{\input{plot/bad1_M.tex}}
      
      \caption{Scenario that has initially unknown moving obstacles (with speed change).}
      
\end{figure}
\end{comment}

\subsection{Result of scenario with share-space working area}

To show that the proposed EUA-MPC can tackle the problem in the previous section, we design a scenario which is common in human-robot share-space working area. The goal for the robot is the same as in the previous. In the beginning, the human worker walks (walking mode) in constant acceleration towards and stops around $y=0$. Once the worker stops, he/she starts to work in the area and moves back and forth in a small range(working mode). To successfully pass the working area, the robot needs to be able to determine the size of the working area and not be overreacting to the human small but inconsistent movement. 

Simulation results are shown in Fig.~\ref{fig:t_wo} and Fig.~\ref{fig:t_w}. We can see that EUA-MPC has a overall smooth closed-loop trajectory, while traditional MPC experience oscillation on the open-loop prediction due to the worker's small movement in working mode. In corresponding, Fig.~\ref{fig:m_w} also shows that EUA-MPC recovers faster than traditional MPC (Fig.~\ref{fig:m_wo}) after the worker switch to working mode. In Fig.~\ref{fig:c_open} we can see that having the knowledge of the size of the working area, EUA-MPC can plan safely around the worker while not being overreacting to the small movement of the worker. On the other hand, traditional MPC reacts strongly to the speed change and results in open-loop trajectory with high cost. In Fig.~\ref{fig:c_close} we can see that the cost with EUA-MPC is the same as traditional MPC in the first 13 steps but noticeably smaller afterwords. This is because EUA-MPC can better utilize the share-space therefore has better overall performance.
\begin{figure}[t]
      \centering
      \subfloat[Simulation result with traditional MPC.\label{fig:t_wo}]{\input{plot/tr_wo.tex}}\\
      \subfloat[Simulation result with EUA-MPC.\label{fig:t_w}]{\input{plot/tr_w.tex}}    
      
      \caption{Scenario that has oscillating moving obstacles.}      
\end{figure}


\begin{figure}[t]
      \centering     
      \subfloat[$M$-analysis for simulation result with traditional MPC.\label{fig:m_wo}]{\input{plot/m_stable_wo.tex}}\\
      \subfloat[$M$-analysis for simulation result with EUA-MPC.\label{fig:m_w}]{\input{plot/m_stable.tex}}\\
      \subfloat[Comparison on open-loop cost between traditional MPC and EUA-MPC.\label{fig:c_open}]{\input{plot/cost_open.tex}}\\
      \subfloat[Comparison on closed-loop cost between traditional MPC and EUA-MPC.\label{fig:c_close}]{\input{plot/Cost_close.tex}}     
      
      \caption{Performance comparison between MPC and EUA-MPC.}
      
\end{figure}







\begin{comment}



\subsection{Result of scenario with single static obstacle}
In this scenario, there is only one static obstacle. This is the scenario as discussed in section 2, where the MPC problem is time invariant. 

The simulation result is shown in Fig.~\ref{fig:1_1}. In the figure, the planned trajectory is marked by gray-star-line of which the gray-color gets darker as time step increases. We can see that the robot successfully track the line while avoiding collision. It is clear from the figure that the last several action locations planned at each time step are one on top of another. This can be taken as an indication of stability. 


Figure~\ref{fig:single_m} shows the number $M$ for $M$-analysis at each action location. The result in Fig.~\ref{fig:single_m} shows that the system is 20-settling once it has run for a sufficient period of time. Note that 20-settling is the highest possible status that a system with prediction horizon of 20 can reach, which is the case in this simulation. If we decrease the sampling time to one fifth of the original, i.e, $\Delta t_{new}=0.2\Delta t_{original}$, it takes less time for the system to reach 20-settling (Fig.~\ref{fig:single_m}). In the figure, the system reaches 20-settling at the $49^{th}$ action location. The run-time at this point is almost equivalent to the run-time at the $10^{th}$ action location in Fig.~\ref{fig:single_m}. This result indicates that decreasing sampling time will increase $M$.

Notice that there is a high peak in $M$ around the $35^{th}$ action location in Fig.~\ref{fig:single_m_0.1Hz} (and a jump at $6^{th}$ in Fig.~\ref{fig:single_m}). This is because these action locations around the peak are close to the obstacle and do not have much space to be adjust. Therefore, these action locations do not change much throughout time and $M$ for $M$-analysis is higher. We call these action locations which are fixed due to the existence of the obstacle critical cation locations. After passing the critical action locations, the robot again has freedom to adjust its planning to best fit the cost function. The adjustment causes $M$ to drop, but soon after, the system reaches to 20-settling and perfectly track the line with constant speed. 

Another way to analyze stability is to look at the cost change. Define path$_k$ as $\mathbf{x}_{k}^{p} := [x_{k}^{k-1},x_{k+1}^{k},\ldots]$ (Fig.~\ref{fig:cost1}). Increase of the index $k$ means the path is starting further and further away from disturbance, i.e., the obstacle, which is located close to the robot's initial location. Therefore, it is expected that the cost will decrease as $k$ increases, which indicates that the robot is stably doing better and better according to what the cost function wants it to do. This expectation meets perfectly with Fig.~\ref{fig:costplot}. 


\begin{figure}[t]
      \centering
      \subfloat[ Simulation result of single static obstacle.\label{fig:1_1}]{\input{plot/single.tex}}\\
      \subfloat[ $M$-analysis for scenario that has known static obstacle.\label{fig:single_m}]{\input{plot/singleM.tex}}\\
      \subfloat[$M$-analysis for scenario that has known static obstacle with increased sampling rate.\label{fig:single_m_0.1Hz}]{\input{plot/simgleM_2.tex}}
      
      \caption{Scenario that has known static obstacle.}
      
\end{figure}



\begin{figure}[t]
      \centering
      \subfloat[ Illustration of path$_k$ (the diagonal lines).\label{fig:cost1}]{\includegraphics[width=8cm]{src/1_3_path.png}}\\
      \subfloat[Cost VS path.\label{fig:costplot}]{\input{plot/cost_vs_path.tex}}
      
      \caption{Convergence of path cost.}
      
\end{figure}



\subsection{Result of scenario with initially unknown static obstacle}
In this scenario, the robot does not know all the obstacle location at the beginning, and has only limited ``eye sight," i.e., only the information of the environment within the range starting from 20 meters ahead to its current position. The robot is expected to execute this MPC motion planning and adjust it's planned trajectory to avoid collision once it ``sees" the obstacle.

The result of this scenario is shown in Fig.~\ref{fig:2_1}. At the beginning, the third obstacle on the right is unknown to the robot. After detecting the third obstacle, the robot corrects its planned trajectory to avoid the obstacle and completes its intention successfully.

The $M$-analysis discussed previously can also be applied to this scenario even though the environment is changing. Since the analysis strategy of this work focus on local conversions at each action locations, i.e., every point in the trajectories, the analysis can still be done although the planned locations change a lot due to environment changes. This directly demonstrate the strength of the proposed $M$-analysis. The result of $M$-analysis is shown in Fig.~\ref{fig:2_2}. From the plot we can see that $M$ begins to increase slower after the $16^{th}$ action location, this is exactly where the robot detects the obstacle and plans the new trajectory to avoid collision. The $26^{th}$ to the $30^{th}$ are the critical action locations, therefore, have higher $M$. After passing by the obstacle, the robot adjusts its planning to best lower the cost and then track the line with constant speed steadily. Throughout the process from detection to reaching 20-settling, the system is at least 14-settling. Once the environment stops changing, the robot system reaches to 20-settling, which agrees with the result from the static-obstacle-scenario.     




\begin{figure}[t]
      \centering
      \subfloat[Simulation result of scenario that has initially unknown static obstacle.\label{fig:2_1}]{\input{plot/multi.tex}}\\
      \subfloat[$M$-analysis for scenario that has initially unknown static obstacle.\label{fig:2_2}]{\input{plot/multiM.tex}}
      
      \caption{Scenario that has initially unknown static obstacle.}
      
\end{figure}





\subsection{Result of scenario with initially unknown moving obstacle}
In this scenario, there exist two static obstacles (shown in green) and a moving obstacle (shown in blue). The moving obstacle is not observed by the robot at the beginning. Once the robot sees this obstacle, it also observes the obstacle's movements and assume that the obstacle is moving in constant acceleration. Therefore, the ego robot is able to predict the future position of the obstacle and conduct planning accordingly. 


In Fig.~\ref{fig:3_3}, the moving obstacle is assumed to be moving in constant speed once detected since the acceleration observed is zero. However, the obstacle will change its speed at some point after detection. In the simulation, after time step $t=20$, the obstacle changes its speed and from moving along negative $x$-axis to positive $y$-axis. From Fig.~\ref{fig:3_3} (b), we can see that the robot adjusts the planned trajectory to best utilize the space once it detects the speed change and avoids the obstacles successfully. From the $M$-analysis plot of this scenario (Fig.~\ref{fig:3_4}), we can also see that the system maintains $15$-settling even though the environment is changing though out time. The result indicates that as long as there is no sudden change accruing close before an action location is executed, the robot can best utilize the new information and successfully plan a smooth trajectory with both traditional MPC and EUA-MPC.

To show the limitation of traditional MPC, an extreme case is tested.  



\begin{figure}[t]
      \centering
      \subfloat[Simulation result of scenario that has initially unknown moving obstacles (with speed change).\label{fig:3_3}]{\input{plot/move.tex}}\\
      \subfloat[$M$-analysis for scenario that has initially unknown moving obstacles (with speed change).\label{fig:3_4}]{\input{plot/moveM.tex}}
      
      \caption{Scenario that has initially unknown moving obstacles (with speed change).}
      
\end{figure}

\subsection{$M$-analysis with less stable trajectory}

This section shows that $M$-analysis can also point out the action locations in the implemented trajectory which is dynamically unreasonable. Such trajectory occurs when the environment changes rapidly. In this simulation scenario, we use random initial trajectory and also make the blue obstacle oscillate its moving speed between $-1$ and $1$ on the $y$ direction at every time step. From Fig.~\ref{fig:bad1} we can see that the action locations near the obstacle (around $k=40$) have a zigzagging shape and in Fig.~\ref{fig:badM}, these action locations also show a decrease in $M$. This indicates that the trajectory is jumping among local optima and we can say that the MPC controller performance is not as stable compared with the previous scenarios.

\begin{figure}[t]
      \centering
      \subfloat[Simulation scenario resulting in dynamically unreasonable trajectory.\label{fig:bad1}]{\input{plot/bad1.tex}}\\
      \subfloat[$M$-analysis for scenario that resulting in dynamically unreasonable trajectory.\label{fig:badM}]{\input{plot/bad1_M.tex}}
      
      \caption{Scenario resulting in dynamically unreasonable trajectory.}    
\end{figure}

\subsection{Relationship between $M$ and $H$}

In industries, choosing a prediction horizon to be large enough is a common way to guarantee stability \cite{mayne2000constrained}. Therefore, we examined the relationship between the prediction horizon $H$ and the resulting $M$ for $M$-analysis. The scenario that has unknown moving obstacle is used here. Define the largest possible $M$ at each action location as $M_{max,k}$, where $M_{max,k} = k-1$ for $k\leq H+1$, and $M_{max,k} = H$ for $k>H+1$. In Fig.~\ref{fig:HM20}, systems with larger ($H>20$) prediction horizon reach $20$-settling (which is a guarantee that the location will not change much within 20 sampling steps before it is executed) faster than the system with $H=20$. Interestingly, all these systems reach $M=20$ in the range after $k=27$, which is the critical action location, but before $k=32$, whereas system with $H=20$ reaches $20$-settling not until after $k=45$. Figure~\ref{fig:HM} shows the smallest $M$ after $k$ reaches $H+1$ for each prediction horizon. It is clear that the smallest $M$ among all action location increase with $H$. Note that large $H$ makes the problem computationally heavy, which should be avoided if possible. We conclude that the horizon can be considered large enough if it can cover the last critical action location, in this case, when $H>27$.

 


\begin{figure}[t]
      \centering
      \input{plot/M_max.tex} 
      \caption{Difference between simulated $M$ and $M_{max,k}$ for $H=20$ (with speed change). }
      \label{fig:HM20}
\end{figure}

\begin{figure}[t]
      \centering
      \input{plot/M_H.tex} 
      \caption{Smallest $M$ for each prediction horizon. }
      \label{fig:HM}
\end{figure}

\begin{figure*}
 \centering
  \begin{tabular}{@{}ccc@{}}
  
   \begin{minipage}{.3\textwidth}
    \includegraphics[width=\textwidth]{plot/tu1.jpg}
   \captionof*{figure}{At time step t=2}
   \end{minipage} &
    \begin{minipage}{.3\textwidth}
    \includegraphics[width=\textwidth]{plot/tu2.png}
   \captionof*{figure}{At time step t=32}
   \end{minipage} &
      \begin{minipage}{.3\textwidth}
    \includegraphics[width=\textwidth]{plot/tu3.png}
   \captionof*{figure}{At time step t=41}
   \end{minipage}\\
      \begin{minipage}{.3\textwidth}
    \includegraphics[width=\textwidth]{plot/tu4.png}
   \captionof*{figure}{At time step t=57}
   \end{minipage} &
    \begin{minipage}{.3\textwidth}
    \includegraphics[width=\textwidth]{plot/tu5.png}
    \captionof*{figure}{At time step t=80}
   \end{minipage} &
      \begin{minipage}{.3\textwidth}
    \includegraphics[width=\textwidth]{plot/tu6.png}
    \captionof*{figure}{At time step t=91}
   \end{minipage}\\
  \end{tabular}
  \caption{Experiment result of robot avoiding an obstacle.}
  \label{fig:ex}
\end{figure*} 

\subsection{Experiment set up}
To verify whether the planned trajectory is dynamically reasonable for a mobile robot to execute, the MPC-CFS (with $H=20$) controller is tested on TurtleBot3, which is  developed by ROBOTIS. TurtleBot3 is a ROS standard platform robot. The MPC-CFS controller is running in MATLAB on a separate laptop with an 2.8GHz Intel Core i7-7700HQ.

Since the dynamics is not included in the MPC problem, we need an additional tracking controller to calculate the suitable command for the robot to execute the planned trajectory. Here we used an iterative LQR (ILQR) controller \cite{tassa2012synthesis}. The cost function is designed to minimize the tracking error and also the robot's acceleration. The final control input at the first time step is chosen to be the the control command for the robot.

\subsection{Experiment result}
Similar to the simulation, the goal for the robot is to move along a line, $y=0$, in the positive $x$-axis direction, while avoiding obstacles and maintaining constant speed which also points along the positive $x$-axis.

The experiment result is shown in Fig.~\ref{fig:ex} and Fig.~\ref{fig:trajectory}, where we can see that the robot can successfully avoid the obstacle and merge back to the original route. Control command is shown in Fig.~\ref{fig:command}.

The proposed $M$-analysis can also be applied in this scenario. If we use the original planning problem ((1)$\sim$(3)), the infeasible starting state at each time step will cause the robot to move in a violent manner. However, after introducing slack variables, the planning results in smoother trajectory. From Fig.~\ref{fig:msettling} we can see that after the first several steps, the whole system maintains at least $13$-settling. After passing by the obstacle ($k>80$), $M$ goes to and maintains at $20$, which indicates that the robot has settled back to track $y=0$. 


\begin{figure}[t]
      \centering
      \input{plot/video.tex} 
      \caption{ Implemented trajectory in the experiment. }
      \label{fig:trajectory}
\end{figure}

\begin{figure}[t]
      \centering
      \includegraphics[width=9cm]{plot/video_nice.eps}
      
      \caption{Control command in the experiment. }
      \label{fig:command}
\end{figure}

\begin{figure}[t]
      \centering
      \input{plot/videoM.tex} 
      \caption{$M$-analysis for the experiment. }
      \label{fig:msettling}
\end{figure}
\end{comment}


\section{EXPERIMENT RESULT}


\subsection{Experiment set up}
To verify the performance, the EUA-MPC (with $H=20$) controller is tested on TurtleBot3, which is  developed by ROBOTIS. TurtleBot3 is a ROS standard platform robot. The MPC-CFS controller is running in MATLAB on a separate laptop with an 2.8GHz Intel Core i7-7700HQ. An iterative LQR (ILQR) controller \cite{tassa2012synthesis} is used for better tracking performance.

\subsection{Experiment result}
Similar to the simulation scenario, we have the ego robot running EUA-MPC and another remote-controlled robot representing the worker.

The experiment result is shown in Fig.~\ref{fig:ex} and Fig.~\ref{fig:trajectory}, where we can see that the robot can successfully avoid the obstacle and merge back to the original route without over reacting to the worker's movement in the working area. Control command is shown in Fig.~\ref{fig:command}.

The proposed $M$-analysis can also be applied in this scenario. If we use the original planning problem ((1)$\sim$(3)), the infeasible starting state at each time step will cause the robot to move in a violent manner. However, after introducing slack variables, the planning results in smoother trajectory. From Fig.~\ref{fig:msettling} we can see that after the first several steps, the whole system maintains at least $13$-settling. After passing by the obstacle ($k>80$), $M$ goes to and maintains at $20$, which indicates that the robot has settled back to track $y=0$. 


\section{Conclusion}

This paper proposed a new method, EUA-MPC to handle common time-variant scenario in industrial HRI system. To better utilize the shared space, a movement tracking and predicting module determined what the worker/robot's mode was and keep track of the uncertainty index. Given these information, EUA-MPC constructed a proper state space for the optimization problem and the result was implemented which completed one EUA-MPC loop. To evaluate the proposed method, $M$-analysis, considered the local convergence of the open-loop trajectory. Simulation results showed that a robot that implemented the EUA-MPC was capable of dealing with dynamic environment, resulting in a smooth closed-loop trajectory, even if the motion of the worker/robot's was not predictable, as long as the switch in between modes were not frequent. It was also shown that the cost was reduced sufficiently in EUA-MPC for both open-loop cost and closed-loop cost. Finally, experiment on Turtlebot3 showed that the proposed EUA-MPC controller performed well. In the future, we will improve the movement tracking and predicting module so that EUA-MPC can deal with more complicated environments. 



\bibliography{root(ACC)}
\bibliographystyle{IEEEtran}


\end{document}







